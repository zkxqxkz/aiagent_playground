; Function Attrs: nounwind
define i32 @_ZN8problems8problem36matmulB2v1B38c8tJTIeFIjxB2IKSgI4CrvQClQZ6FczSBAA_3dEiii5ArrayIfLi2E1A7mutable7alignedE5ArrayIfLi2E1A7mutable7alignedE({ i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }* noalias nocapture writeonly %retptr, { i8*, i32, i8*, i8*, i32 }** noalias nocapture writeonly %excinfo, i32 %arg.m, i32 %arg.k, i32 %arg.n, i8* %arg.A.0, i8* nocapture readnone %arg.A.1, i64 %arg.A.2, i64 %arg.A.3, float* %arg.A.4, i64 %arg.A.5.0, i64 %arg.A.5.1, i64 %arg.A.6.0, i64 %arg.A.6.1, i8* %arg.B.0, i8* nocapture readnone %arg.B.1, i64 %arg.B.2, i64 %arg.B.3, float* %arg.B.4, i64 %arg.B.5.0, i64 %arg.B.5.1, i64 %arg.B.6.0, i64 %arg.B.6.1) local_unnamed_addr {
entry:
  tail call void @NRT_incref(i8* %arg.A.0)
  tail call void @NRT_incref(i8* %arg.B.0)
  %.13.i.i = sext i32 %arg.m to i64
  %.14.i.i = sext i32 %arg.k to i64
  %.15.i.i = icmp slt i32 %arg.m, 0
  %.24.i.i = icmp slt i32 %arg.k, 0
  %or.cond.i = select i1 %.15.i.i, i1 true, i1 %.24.i.i
  br i1 %or.cond.i, label %B0.if, label %B0.endif.endif.i.i, !prof !0

B0.endif.endif.i.i:
  %.38.i.i = mul nsw i64 %.14.i.i, %.13.i.i
  %.42.i.i = shl nsw i64 %.14.i.i, 2
  %.43.i.i = tail call { i64, i1 } @llvm.smul.with.overflow.i64(i64 %.38.i.i, i64 4)
  %.45.i.i = extractvalue { i64, i1 } %.43.i.i, 1
  br i1 %.45.i.i, label %B0.if, label %B0.endif.endif.endif.i.i, !prof !1

B0.endif.endif.endif.i.i:
  %.44.i.i = extractvalue { i64, i1 } %.43.i.i, 0
  %.7.i.i.i.i = tail call i8* @NRT_MemInfo_alloc_aligned(i64 %.44.i.i, i32 32), !noalias !2
  %.8.i.i.i.i = icmp eq i8* %.7.i.i.i.i, null
  br i1 %.8.i.i.i.i, label %B0.if, label %B0.endif.endif, !prof !1

common.ret:
  %common.ret.op = phi i32 [ 0, %B104 ], [ 1, %B0.if ]
  ret i32 %common.ret.op

B104:
  %retptr.repack = getelementptr inbounds { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 0
  store i8* %.7.i.i.i.i, i8** %retptr.repack, align 8
  %retptr.repack7 = getelementptr inbounds { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 1
  store i8* null, i8** %retptr.repack7, align 8
  %retptr.repack9 = getelementptr inbounds { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 2
  store i64 %.38.i.i, i64* %retptr.repack9, align 8
  %retptr.repack11 = getelementptr inbounds { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 3
  store i64 4, i64* %retptr.repack11, align 8
  %retptr.repack13 = getelementptr inbounds { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 4
  store float* %.6.i1.i.i, float** %retptr.repack13, align 8
  %retptr.repack15.repack = getelementptr inbounds { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 5, i64 0
  store i64 %.13.i.i, i64* %retptr.repack15.repack, align 8
  %retptr.repack15.repack19 = getelementptr inbounds { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 5, i64 1
  store i64 %.14.i.i, i64* %retptr.repack15.repack19, align 8
  %retptr.repack17.repack = getelementptr inbounds { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 6, i64 0
  store i64 %.42.i.i, i64* %retptr.repack17.repack, align 8
  %retptr.repack17.repack21 = getelementptr inbounds { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }, { i8*, i8*, i64, i64, float*, [2 x i64], [2 x i64] }* %retptr, i64 0, i32 6, i64 1
  store i64 4, i64* %retptr.repack17.repack21, align 8
  tail call void @NRT_decref(i8* %arg.B.0)
  tail call void @NRT_decref(i8* %arg.A.0)
  br label %common.ret

B0.if:
  %excinfo.1.0.ph = phi { i8*, i32, i8*, i8*, i32 }* [ @.const.picklebuf.125878260706496, %entry ], [ @.const.picklebuf.125878260707136, %B0.endif.endif.i.i ], [ @.const.picklebuf.125878261078144, %B0.endif.endif.endif.i.i ]
  store { i8*, i32, i8*, i8*, i32 }* %excinfo.1.0.ph, { i8*, i32, i8*, i8*, i32 }** %excinfo, align 8
  br label %common.ret

B0.endif.endif:
  %.5.i.i.i = getelementptr i8, i8* %.7.i.i.i.i, i64 24
  %0 = bitcast i8* %.5.i.i.i to float**
  %.6.i1.i.i = load float*, float** %0, align 8, !noalias !15
  %.32.i.i = shl nsw i64 %.38.i.i, 2
  %.33.i.i = bitcast float* %.6.i1.i.i to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %.33.i.i, i8 0, i64 %.32.i.i, i1 false), !noalias !16
  %.18856.not = icmp eq i32 %arg.m, 0
  br i1 %.18856.not, label %B104, label %B32.endif.lr.ph

B32.endif.lr.ph:
  %.30953.not = icmp slt i32 %arg.n, 1
  %.611 = ptrtoint float* %arg.A.4 to i64
  %.717 = ptrtoint float* %arg.B.4 to i64
  %.43050.not = icmp eq i32 %arg.k, 0
  %or.cond = select i1 %.30953.not, i1 true, i1 %.43050.not
  br i1 %or.cond, label %B104, label %B32.endif.us.us.preheader

B32.endif.us.us.preheader:
  %wide.trip.count79 = zext i32 %arg.m to i64
  %wide.trip.count74 = zext i32 %arg.n to i64
  %wide.trip.count = zext i32 %arg.k to i64
  %1 = add nsw i64 %wide.trip.count, -1
  %xtraiter = and i64 %wide.trip.count, 3
  %2 = icmp ult i64 %1, 3
  %unroll_iter = and i64 %wide.trip.count, 4294967292
  %lcmp.mod.not = icmp eq i64 %xtraiter, 0
  #pragma clang loop unroll(full)
  #pragma clang loop vectorize(enable)
  #pragma omp parallel for
  br label %B32.endif.us.us

B32.endif.us.us:
  %indvars.iv76 = phi i64 [ 0, %B32.endif.us.us.preheader ], [ %indvars.iv.next77, %B42.B30.loopexit_crit_edge.split.us.us.us ]
  %.507.us.us = mul nsw i64 %indvars.iv76, %.14.i.i
  %.509.us.us = getelementptr float, float* %.6.i1.i.i, i64 %.507.us.us
  %.610.us.us = mul i64 %indvars.iv76, %arg.A.6.0
  %.612.us.us = add i64 %.610.us.us, %.611
  br label %B44.endif.us.us.us

B44.endif.us.us.us:
  %indvars.iv71 = phi i64 [ %indvars.iv.next72, %B54.B42.loopexit_crit_edge.us.us.us ], [ 0, %B32.endif.us.us ]
  %.570.us.us.us = getelementptr float, float* %.509.us.us, i64 %indvars.iv71
  %.778.us.us.us = mul i64 %indvars.iv71, %arg.B.6.1
  %.718.us.us.us = add i64 %.778.us.us.us, %.717
  %.571.us.us.us.pre = load float, float* %.570.us.us.us, align 4
  br i1 %2, label %B54.B42.loopexit_crit_edge.us.us.us.unr-lcssa, label %B56.us.us.us

B56.us.us.us:
  %.571.us.us.us = phi float [ %.787.us.us.us.3, %B56.us.us.us ], [ %.571.us.us.us.pre, %B44.endif.us.us.us ]
  %indvars.iv = phi i64 [ %indvars.iv.next.3, %B56.us.us.us ], [ 0, %B44.endif.us.us.us ]
  %niter = phi i64 [ %niter.next.3, %B56.us.us.us ], [ 0, %B44.endif.us.us.us ]
  %indvars.iv.next = or i64 %indvars.iv, 1
  %.671.us.us.us = mul i64 %indvars.iv, %arg.A.6.1
  %.673.us.us.us = add i64 %.612.us.us, %.671.us.us.us
  %.674.us.us.us = inttoptr i64 %.673.us.us.us to float*
  %.675.us.us.us = load float, float* %.674.us.us.us, align 4
  %.716.us.us.us = mul i64 %indvars.iv, %arg.B.6.0
  %.780.us.us.us = add i64 %.718.us.us.us, %.716.us.us.us
  %.781.us.us.us = inttoptr i64 %.780.us.us.us to float*
  %.782.us.us.us = load float, float* %.781.us.us.us, align 4
  %.786.us.us.us = fmul float %.675.us.us.us, %.782.us.us.us
  %.787.us.us.us = fadd float %.571.us.us.us, %.786.us.us.us
  store float %.787.us.us.us, float* %.570.us.us.us, align 4
  %indvars.iv.next.1 = or i64 %indvars.iv, 2
  %.671.us.us.us.1 = mul i64 %indvars.iv.next, %arg.A.6.1
  %.673.us.us.us.1 = add i64 %.612.us.us, %.671.us.us.us.1
  %.674.us.us.us.1 = inttoptr i64 %.673.us.us.us.1 to float*
  %.675.us.us.us.1 = load float, float* %.674.us.us.us.1, align 4
  %.716.us.us.us.1 = mul i64 %indvars.iv.next, %arg.B.6.0
  %.780.us.us.us.1 = add i64 %.718.us.us.us, %.716.us.us.us.1
  %.781.us.us.us.1 = inttoptr i64 %.780.us.us.us.1 to float*
  %.782.us.us.us.1 = load float, float* %.781.us.us.us.1, align 4
  %.786.us.us.us.1 = fmul float %.675.us.us.us.1, %.782.us.us.us.1
  %.787.us.us.us.1 = fadd float %.787.us.us.us, %.786.us.us.us.1
  store float %.787.us.us.us.1, float* %.570.us.us.us, align 4
  %indvars.iv.next.2 = or i64 %indvars.iv, 3
  %.671.us.us.us.2 = mul i64 %indvars.iv.next.1, %arg.A.6.1
  %.673.us.us.us.2 = add i64 %.612.us.us, %.671.us.us.us.2
  %.674.us.us.us.2 = inttoptr i64 %.673.us.us.us.2 to float*
  %.675.us.us.us.2 = load float, float* %.674.us.us.us.2, align 4
  %.716.us.us.us.2 = mul i64 %indvars.iv.next.1, %arg.B.6.0
  %.780.us.us.us.2 = add i64 %.718.us.us.us, %.716.us.us.us.2
  %.781.us.us.us.2 = inttoptr i64 %.780.us.us.us.2 to float*
  %.782.us.us.us.2 = load float, float* %.781.us.us.us.2, align 4
  %.786.us.us.us.2 = fmul float %.675.us.us.us.2, %.782.us.us.us.2
  %.787.us.us.us.2 = fadd float %.787.us.us.us.1, %.786.us.us.us.2
  store float %.787.us.us.us.2, float* %.570.us.us.us, align 4
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv, 4
  %.671.us.us.us.3 = mul i64 %indvars.iv.next.2, %arg.A.6.1
  %.673.us.us.us.3 = add i64 %.612.us.us, %.671.us.us.us.3
  %.674.us.us.us.3 = inttoptr i64 %.673.us.us.us.3 to float*
  %.675.us.us.us.3 = load float, float* %.674.us.us.us.3, align 4
  %.716.us.us.us.3 = mul i64 %indvars.iv.next.2, %arg.B.6.0
  %.780.us.us.us.3 = add i64 %.718.us.us.us, %.716.us.us.us.3
  %.781.us.us.us.3 = inttoptr i64 %.780.us.us.us.3 to float*
  %.782.us.us.us.3 = load float, float* %.781.us.us.us.3, align 4
  %.786.us.us.us.3 = fmul float %.675.us.us.us.3, %.782.us.us.us.3
  %.787.us.us.us.3 = fadd float %.787.us.us.us.2, %.786.us.us.us.3
  store float %.787.us.us.us.3, float* %.570.us.us.us, align 4
  %niter.next.3 = add i64 %niter, 4
  %niter.ncmp.3 = icmp eq i64 %niter.next.3, %unroll_iter
  br i1 %niter.ncmp.3, label %B54.B42.loopexit_crit_edge.us.us.us.unr-lcssa, label %B56.us.us.us

B54.B42.loopexit_crit_edge.us.us.us.unr-lcssa:
  %.571.us.us.us.unr = phi float [ %.571.us.us.us.pre, %B44.endif.us.us.us ], [ %.787.us.us.us.3, %B56.us.us.us ]
  %indvars.iv.unr = phi i64 [ 0, %B44.endif.us.us.us ], [ %indvars.iv.next.3, %B56.us.us.us ]
  br i1 %lcmp.mod.not, label %B54.B42.loopexit_crit_edge.us.us.us, label %B56.us.us.us.epil

B56.us.us.us.epil:
  %.571.us.us.us.epil = phi float [ %.787.us.us.us.epil, %B56.us.us.us.epil ], [ %.571.us.us.us.unr, %B54.B42.loopexit_crit_edge.us.us.us.unr-lcssa ]
  %indvars.iv.epil = phi i64 [ %indvars.iv.next.epil, %B56.us.us.us.epil ], [ %indvars.iv.unr, %B54.B42.loopexit_crit_edge.us.us.us.unr-lcssa ]
  %epil.iter = phi i64 [ %epil.iter.next, %B56.us.us.us.epil ], [ 0, %B54.B42.loopexit_crit_edge.us.us.us.unr-lcssa ]
  %indvars.iv.next.epil = add nuw nsw i64 %indvars.iv.epil, 1
  %.671.us.us.us.epil = mul i64 %indvars.iv.epil, %arg.A.6.1
  %.673.us.us.us.epil = add i64 %.612.us.us, %.671.us.us.us.epil
  %.674.us.us.us.epil = inttoptr i64 %.673.us.us.us.epil to float*
  %.675.us.us.us.epil = load float, float* %.674.us.us.us.epil, align 4
  %.716.us.us.us.epil = mul i64 %indvars.iv.epil, %arg.B.6.0
  %.780.us.us.us.epil = add i64 %.718.us.us.us, %.716.us.us.us.epil
  %.781.us.us.us.epil = inttoptr i64 %.780.us.us.us.epil to float*
  %.782.us.us.us.epil = load float, float* %.781.us.us.us.epil, align 4
  %.786.us.us.us.epil = fmul float %.675.us.us.us.epil, %.782.us.us.us.epil
  %.787.us.us.us.epil = fadd float %.571.us.us.us.epil, %.786.us.us.us.epil
  store float %.787.us.us.us.epil, float* %.570.us.us.us, align 4
  %epil.iter.next = add i64 %epil.iter, 1
  %epil.iter.cmp.not = icmp eq i64 %epil.iter.next, %xtraiter
  br i1 %epil.iter.cmp.not, label %B54.B42.loopexit_crit_edge.us.us.us, label %B56.us.us.us.epil, !llvm.loop !19

B54.B42.loopexit_crit_edge.us.us.us:
  %indvars.iv.next72 = add nuw nsw i64 %indvars.iv71, 1
  %exitcond75.not = icmp eq i64 %indvars.iv.next72, %wide.trip.count74
  br i1 %exitcond75.not, label %B42.B30.loopexit_crit_edge.split.us.us.us, label %B44.endif.us.us.us

B42.B30.loopexit_crit_edge.split.us.us.us:
  %indvars.iv.next77 = add nuw nsw i64 %indvars.iv76, 1
  %exitcond80.not = icmp eq i64 %indvars.iv.next77, %wide.trip.count79
  br i1 %exitcond80.not, label %B104, label %B32.endif.us.us
}